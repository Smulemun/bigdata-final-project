{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ebfd49a-26b4-4040-889a-889f8436dd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml import Pipeline\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StringType, FloatType, IntegerType\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, Word2Vec, Tokenizer, RegexTokenizer\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6339c12a-2873-4b0b-a05b-0549fb719515",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "team = 16\n",
    "nworkers = 3\n",
    "cores = 1\n",
    "warehouse = \"project/hive/warehouse\"\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "        .appName(\"{} - spark ML\".format(team))\\\n",
    "        .master(\"yarn\")\\\n",
    "        .config(\"hive.metastore.uris\", \"thrift://hadoop-02.uni.innopolis.ru:9883\")\\\n",
    "        .config(\"spark.sql.warehouse.dir\", warehouse)\\\n",
    "        .config(\"spark.sql.avro.compression.codec\", \"snappy\")\\\n",
    "        .config('spark.executor.instances', nworkers)\\\n",
    "        .config(\"spark.executor.cores\", cores)\\\n",
    "        .config(\"spark.executor.cpus\", cores)\\\n",
    "        .config(\"spark.executor.memory\", \"4g\")\\\n",
    "        .enableHiveSupport()\\\n",
    "        .getOrCreate()\n",
    "        # \n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963d0b24-2ec1-4dfe-9dca-e10f73caa0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"USE team16_projectdb\").show()\n",
    "spark.sql(\"SELECT * FROM ecom_part_buck\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09238c16-b4ba-4544-91be-2ac7fcf71e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT event_types, COUNT(*) FROM ecom_part_buck GROUP BY event_types\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbe2d2e-7df0-4f3f-b8c5-6552956b9929",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.format(\"avro\").table('team16_projectdb.ecom_part_buck')\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7683c2d-b822-4b4f-aeca-209d51ef979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyclicTransformer(Transformer):\n",
    "    def __init__(self, input_col):\n",
    "        super(CyclicTransformer, self).__init__()\n",
    "        self.input_col = input_col\n",
    "\n",
    "    def _transform(self, df):\n",
    "        extract_year = F.udf(lambda x: x.year)\n",
    "        extract_month = F.udf(lambda x: x.month)\n",
    "        extract_day = F.udf(lambda x: x.day)\n",
    "        extract_hour = F.udf(lambda x: x.hour)\n",
    "        extract_minute = F.udf(lambda x: x.minute)\n",
    "        extract_second = F.udf(lambda x: x.second)\n",
    "\n",
    "        return df.withColumn('year', extract_year(self.input_col))\\\n",
    "                 .withColumn('month', extract_month(self.input_col))\\\n",
    "                 .withColumn('day', extract_day(self.input_col))\\\n",
    "                 .withColumn('hour', extract_hour(self.input_col))\\\n",
    "                 .withColumn('minute', extract_minute(self.input_col))\\\n",
    "                 .withColumn('second', extract_second(self.input_col))\\\n",
    "                 .withColumn('month_sin', F.sin(F.col('month') * 2 * math.pi / 12))\\\n",
    "                 .withColumn('month_cos', F.cos(F.col('month') * 2 * math.pi / 12))\\\n",
    "                 .withColumn('day_sin', F.sin(F.col('day') * 2 * math.pi / 31))\\\n",
    "                 .withColumn('day_cos', F.cos(F.col('day') * 2 * math.pi / 31))\\\n",
    "                 .withColumn('hour_sin', F.sin(F.col('hour') * 2 * math.pi / 24))\\\n",
    "                 .withColumn('hour_cos', F.cos(F.col('hour') * 2 * math.pi / 24))\\\n",
    "                 .withColumn('minute_sin', F.sin(F.col('minute') * 2 * math.pi / 60))\\\n",
    "                 .withColumn('minute_cos', F.cos(F.col('minute') * 2 * math.pi / 60))\\\n",
    "                 .withColumn('second_sin', F.sin(F.col('second') * 2 * math.pi / 60))\\\n",
    "                 .withColumn('second_cos', F.cos(F.col('second') * 2 * math.pi / 60))\\\n",
    "                 .drop(self.input_col).drop('month').drop('day')\\\n",
    "                 .drop('hour').drop('minute').drop('second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9ac9bf-780b-4fb1-bb07-b851711f90e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclic_trans = CyclicTransformer('event_time')\n",
    "data = cyclic_trans.transform(data)\n",
    "data.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a9d48c-65d9-4572-8e24-3094f2e67b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.na.drop(subset=data.columns)\n",
    "data = data.filter(data.brand != '')\n",
    "data = data.filter(data.category_code != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8bcc0d-6821-4748-8a1f-d8c13797f126",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af78813-7816-4944-ba95-db938f282641",
   "metadata": {},
   "source": [
    "data.groupBy(\"category_code\").count().withColumnRenamed(\"count\", \"num\").orderBy(F.col(\"num\").desc()).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677dc8d3-03e0-40b9-be4d-b7c8091789cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_type_to_rating = F.udf(lambda x: 1 if x == 'purchase' else 0 if x == 'cart' else -1, IntegerType())\n",
    "data = data.withColumn('rating', event_type_to_rating('event_types')).drop('event_types')\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb0bc08-11fd-4174-a40e-b226babc4219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# brand preprocessing: take only popular brands (> 10000 interactions)\n",
    "\n",
    "brand_counts = data.groupBy(\"brand\").count()\n",
    "rare_brands = brand_counts.filter(F.col(\"count\") < 10000).select(\"brand\").rdd.flatMap(lambda x: x).collect()\n",
    "data = data.withColumn(\"brand\", F.when(F.col(\"brand\").isin(rare_brands), \"other\").otherwise(F.col(\"brand\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf60d01-71cf-4d53-a874-6728442134c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding of brand\n",
    "\n",
    "indexer = StringIndexer(inputCol='brand', outputCol=\"brand_indexed\")\n",
    "oh_encoder = OneHotEncoder(inputCol=indexer.getOutputCol(), outputCol=\"brand_encoded\")\n",
    "\n",
    "brand_pipeline = Pipeline(stages=[indexer, oh_encoder]).fit(data)\n",
    "data = brand_pipeline.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d45f6e-c636-4731-9e58-dd3337c91e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = data.randomSplit([0.6, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb281e6c-43c8-4a73-a981-90155527568b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator \n",
    "from pyspark.ml.recommendation import ALS \n",
    "\n",
    "als = ALS(maxIter=5,\n",
    "          regParam=0.01,\n",
    "          userCol=\"user_id\",\n",
    "          itemCol=\"product_id\",\n",
    "          ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\")\n",
    "\n",
    "als_model = als.fit(train_data)\n",
    "\n",
    "predictions = als_model.transform(test_data)\n",
    "\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aff356-4642-4583-93cb-b051aec1ad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"rating\", predictionCol=\"predictions\")\n",
    "rmse = evaluator.evaluate(predictions, {evaluator.metricName: \"rmse\"})\n",
    "r2 = evaluator.evaluate(predictions, {evaluator.metricName: \"r2\"})\n",
    "print(\"Root-mean-square error = \" + str(rmse) + '\\n' + 'R2 = ' + str(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9b1083-dc1e-46b3-ab92-b6ebb916b1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
